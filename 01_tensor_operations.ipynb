{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "01-tensor-operations.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tosin-doc/Basic-Pytorch-Functions/blob/main/01_tensor_operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9E3eZXIttMa"
      },
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!pip install jovian --upgrade -q\n",
        "import jovian\n",
        "jovian.utils.colab.set_colab_file_id('1R6-UAttiQHZl4k65953hwzZzT8uaTRik')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok419yUkttMe"
      },
      "source": [
        "# Pytorch Functions You Should Know\n",
        "\n",
        "A short introduction about PyTorch and about the chosen functions. \n",
        "\n",
        "- function 1\n",
        "- function 2\n",
        "- function 3\n",
        "- function 4\n",
        "- function 5\n",
        "\n",
        "Before we begin, let's install and import PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlyFcJkbttMe",
        "outputId": "79a5ada9-a271-439d-e153-4a524a8d2330"
      },
      "source": [
        "# Uncomment and run the appropriate command for your operating system, if required\n",
        "\n",
        "# Linux / Binder\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Windows\n",
        "!pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# MacOS\n",
        "# !pip install numpy torch torchvision torchaudio"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: torch==1.7.0+cpu in /usr/local/lib/python3.6/dist-packages (1.7.0+cpu)\n",
            "Requirement already satisfied: torchvision==0.8.1+cpu in /usr/local/lib/python3.6/dist-packages (0.8.1+cpu)\n",
            "Requirement already satisfied: torchaudio==0.7.0 in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0+cpu) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0+cpu) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0+cpu) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.8.1+cpu) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlupBdTNttMn"
      },
      "source": [
        "# Import torch and other required modules\n",
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UF9Ig7CttMn"
      },
      "source": [
        "## Function 1 - torch.addcmul\n",
        "torch.addcmul function helps us in element wise multiplication of the passed in tensors (tensor 1 and tensor 2) take a fraction of it by multiplying with a constant value and summing up the resultant value with the input tensor.\n",
        "\n",
        "The function can be represented as a formula as follows.\n",
        "\n",
        "<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
        "  <msub>\n",
        "    <mtext>out</mtext>\n",
        "    <mi>i</mi>\n",
        "  </msub>\n",
        "  <mo>=</mo>\n",
        "  <msub>\n",
        "    <mtext>input</mtext>\n",
        "    <mi>i</mi>\n",
        "  </msub>\n",
        "  <mo>+</mo>\n",
        "  <mtext>value</mtext>\n",
        "  <mo>&#xD7;</mo>\n",
        "  <msub>\n",
        "    <mtext>tensor1</mtext>\n",
        "    <mi>i</mi>\n",
        "  </msub>\n",
        "  <mo>&#xD7;</mo>\n",
        "  <msub>\n",
        "    <mtext>tensor2</mtext>\n",
        "    <mi>i</mi>\n",
        "  </msub>\n",
        "</math>\n",
        "\n",
        "\n",
        "Function takes in input, value, tensor1 and tensor2 as inputs, create an output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgjop1GxttMo",
        "outputId": "af09c9f6-7eba-410e-e775-02534972f54a"
      },
      "source": [
        "#Example 1\n",
        "# Input Tensor\n",
        "input_t = torch.eye(1,2)\n",
        "\n",
        "#Value\n",
        "value=0.4\n",
        "\n",
        "#Tensor 1 & 2\n",
        "tensor1 = torch.eye(1,2)\n",
        "tensor2 = torch.eye(2,1)\n",
        "\n",
        "# Function\n",
        "torch.addcmul(input_t,value,tensor1,tensor2)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: This overload of addcmul is deprecated:\n",
            "\taddcmul(Tensor input, Number value, Tensor tensor1, Tensor tensor2, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul(Tensor input, Tensor tensor1, Tensor tensor2, *, Number value, Tensor out) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.4000, 0.0000],\n",
              "        [1.0000, 0.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eywqwL58ttMw"
      },
      "source": [
        "In the above example we use identity matrix to understand the functionality of the torch.addmul() function.It should note that the tensor1 and tensor2 is multiplied element wise before being multiplied with the user inputted value. Shape of tensor1 and tensor2 should have size which can be either broadcasted to match either of those are will result in an error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3vkTBqHttMw",
        "outputId": "6c38d38d-6640-4fda-c9cb-e6053f91a977"
      },
      "source": [
        "# Example 2 - \n",
        "input_t = torch.randn(1,4)\n",
        "\n",
        "#Value\n",
        "value=0.4\n",
        "\n",
        "#Tensor 1 & 2\n",
        "tensor1 = torch.randn(1,4)\n",
        "tensor2 = torch.randn(2,1)\n",
        "\n",
        "# Function\n",
        "torch.addcmul(input_t,value,tensor1,tensor2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8645, -1.0327,  0.2428,  0.9353],\n",
              "        [-1.1646, -1.0111,  0.2749,  0.6326]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hngorqDTttMw"
      },
      "source": [
        "Step By Step Breakdown of the above Example\n",
        "\n",
        "1. tensor1 and tensor2 are multiplied element wise\n",
        "2. Value provided by the user is then multiplied element wise with the matrix resulting from above.\n",
        "\n",
        "Input Tensor is then added to the result produced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "g2T95sw8ttMx",
        "outputId": "3ef6f597-9690-4017-d813-4d7022ef993d"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "input_t = torch.randn(1,3)\n",
        "\n",
        "#Value\n",
        "value=0.4\n",
        "\n",
        "#Tensor 1 & 2\n",
        "tensor1 = torch.randn(1,4)\n",
        "tensor2 = torch.randn(3,1)\n",
        "\n",
        "# Function\n",
        "torch.addcmul(input_t,value,tensor1,tensor2)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f0b19d5bd788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WEW8KwCttM0"
      },
      "source": [
        "This function can break in two ways.\n",
        "\n",
        "If the tensor1 and tensor2 element wise multiplication does not match in dimension.\n",
        "The addition of input_t with the result produced doesnâ€™t match in dimension.\n",
        "In the Above case it failed because its not able to add [1,3] tensor with [3,4] produced by the multiplication is not possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLOrBmrittM1"
      },
      "source": [
        "Let's save our work using Jovian before continuing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjLXk0PwttM2"
      },
      "source": [
        "!pip install jovian --upgrade --quiet"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1qE8ulzttM2"
      },
      "source": [
        "import jovian"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "cmmudbRuttM4",
        "outputId": "70c7270f-3045-4d7e-fa3f-af0313f9782f"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/tosin-doc/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/tosin-doc/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbxvjslfttM6"
      },
      "source": [
        "## Function 2 - torch.git\n",
        "\n",
        "torch.gt function allows us in element wise comparision of the two inputs passed. The second argument can be a number that can be broadcasted to match the dimension of the first argument.\n",
        "\n",
        "Mathematically represented as input > other\n",
        "\n",
        "It takes in two arguments input and other\n",
        "\n",
        "*  input is the tensor on which element wise comparison is need to be done.\n",
        "*  other is the tensor value based on which the result is returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Jl7Ps9HttM6",
        "outputId": "46a8e1bf-6bf5-44cc-b6dc-70d4a21d6ae1"
      },
      "source": [
        "\n",
        "# Example 1 - Comparing with a scalar\n",
        "\n",
        "#Input\n",
        "input_t = torch.arange(0,10)\n",
        "\n",
        "# Function\n",
        "torch.gt(input_t,torch.tensor([4]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False, False, False, False,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9VhOfoattM6"
      },
      "source": [
        "In the above example the tensor input is compared with a single value 4 and the result is returned element wise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0FXt1-WttM6",
        "outputId": "9d0175fb-cd5e-42df-8ef5-dad8b479927c"
      },
      "source": [
        "# Example 2 - working\n",
        "\n",
        "#Input\n",
        "input_t = torch.arange(0,9).reshape(3,3)\n",
        "other = torch.tensor([5,2,1,4,7,2,3,1,6]).reshape(3,3)\n",
        "# Function\n",
        "torch.gt(input_t,other)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False,  True],\n",
              "        [False, False,  True],\n",
              "        [ True,  True,  True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PgWNey7ttM6"
      },
      "source": [
        "In the above example we have two tensors of shape 3,3 and each element of input_t is compared with other tensor and the result is produced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "PaBL3EstttM7",
        "outputId": "40a072cb-9c65-4e3e-c524-257d1a8ebc36"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "\n",
        "#Input\n",
        "input_t = torch.arange(0,9).reshape(3,3)\n",
        "other = torch.tensor([5,2,1,4,7,2,3,1,3,5]).reshape(2,5)\n",
        "# Function\n",
        "torch.gt(input_t,other)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-783ea178fb15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (5) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kyQtWeDttM7"
      },
      "source": [
        "Shape of the input and other should match.\n",
        "\n",
        "This function can be used to subset based on the condition of the other tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "wUTrpPl3ttM7",
        "outputId": "183eb262-37bf-479b-cb23-e7d15d894a50"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/tosin-doc/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/tosin-doc/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScvX-AAkttM8"
      },
      "source": [
        "## Function 3 - torch.flatten()\n",
        "\n",
        "As the name suggest the function is used to flatten or convert into a single row from different shape of the tensor. This functionality can also be altered by assigning the start and end dimension of the tensor to flatten it.\n",
        "\n",
        "torch.flatten() takes in one argument and 2 optional argument\n",
        "\n",
        "input is the tensor which is to be flattened\n",
        "start_dimis the dimension along which flattening should be done\n",
        "end_dim is the ending dimension along which flattening should be done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "OPlTpqjQttM8",
        "outputId": "03aa74e2-d567-4aae-b183-b93f6756d4fe"
      },
      "source": [
        "# Example 1 - working\n",
        "# Without any Keyword Arguments\n",
        "\n",
        "input_t = torch.arange(10).reshape(2,5)\n",
        "print(\"Displaying Input tensor\")\n",
        "display(input_t)\n",
        "print(f'{input_t.shape} \\n')\n",
        "\n",
        "# Flattening the tensor\n",
        "print(\"Displaying Flattened Tensor\")\n",
        "\n",
        "torch.flatten(input_t)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Displaying Input tensor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2, 3, 4],\n",
              "        [5, 6, 7, 8, 9]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 5]) \n",
            "\n",
            "Displaying Flattened Tensor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlyM9Ba-ttM8"
      },
      "source": [
        "In this example the input tensor is of shape [2,5] which is then converted into [1,10] through flattening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "qK4195oUttM8",
        "outputId": "55218748-6507-42c2-bac3-005ef30b2d9f"
      },
      "source": [
        "# Example 2 - working\n",
        "# With Keyword Argument start_dim\n",
        "\n",
        "input_t = torch.arange(20).reshape(2,2,5)\n",
        "print(\"Displaying Input tensor\")\n",
        "display(input_t)\n",
        "print(f'{input_t.shape} \\n')\n",
        "\n",
        "# Flattening the tensor\n",
        "print(\"Displaying Flattened Tensor\")\n",
        "\n",
        "torch.flatten(input_t,start_dim=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Displaying Input tensor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2,  3,  4],\n",
              "         [ 5,  6,  7,  8,  9]],\n",
              "\n",
              "        [[10, 11, 12, 13, 14],\n",
              "         [15, 16, 17, 18, 19]]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2, 5]) \n",
            "\n",
            "Displaying Flattened Tensor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
              "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptGu14eJttM8"
      },
      "source": [
        "Explanation about example\n",
        "\n",
        "In the above example input tensor is of shape [2,2,5] and since the tensor is flattened on shape 1 it returns a tensor of shape [2,10]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "J5YsBYEyttM9",
        "outputId": "65838158-5722-4273-8b66-761a8e0f9171"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "\n",
        "input_t = torch.arange(10).reshape(2,5)\n",
        "print(\"Displaying Input tensor\")\n",
        "display(input_t)\n",
        "print(f'{input_t.shape} \\n')\n",
        "\n",
        "# Flattening the tensor\n",
        "print(\"Displaying Flattened Tensor\")\n",
        "\n",
        "torch.flatten(input_t,start_dim=2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Displaying Input tensor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2, 3, 4],\n",
              "        [5, 6, 7, 8, 9]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 5]) \n",
            "\n",
            "Displaying Flattened Tensor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-202e52ce3fbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Displaying Flattened Tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc1E0v90ttM9"
      },
      "source": [
        "The above example breaks because the input tensor is of shape [2,5] and the start dimension is specified as 2. But the value in this case should be between [-2,1].\n",
        "\n",
        "This function can be used when we need to convert the image tensor into a linear unit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "FdAWq_SettM9",
        "outputId": "ad6a58a2-8761-4d71-cada-fc542d57484c"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/tosin-doc/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/tosin-doc/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9kdO0DHttM-"
      },
      "source": [
        "## Function 4 - torch.clamp()\n",
        "\n",
        "torch.clamp function is used to limit the value in the tensor to a needed limit, within the min and max value.\n",
        "\n",
        "Mathematically this function can be represented as\n",
        "\n",
        "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
        "  <msub>\n",
        "    <mi>y</mi>\n",
        "    <mi>i</mi>\n",
        "  </msub>\n",
        "  <mo>=</mo>\n",
        "  <mrow data-mjx-texclass=\"INNER\">\n",
        "    <mo data-mjx-texclass=\"OPEN\">{</mo>\n",
        "    <mtable columnalign=\"left left\" columnspacing=\"1em\" rowspacing=\".2em\">\n",
        "      <mtr>\n",
        "        <mtd>\n",
        "          <mtext>min</mtext>\n",
        "        </mtd>\n",
        "        <mtd>\n",
        "          <mtext>if&#xA0;</mtext>\n",
        "          <msub>\n",
        "            <mi>x</mi>\n",
        "            <mi>i</mi>\n",
        "          </msub>\n",
        "          <mo>&lt;</mo>\n",
        "          <mtext>min</mtext>\n",
        "          <mtext>&#xA0;</mtext>\n",
        "          <msub>\n",
        "            <mi>x</mi>\n",
        "            <mi>i</mi>\n",
        "          </msub>\n",
        "        </mtd>\n",
        "        <mtd>\n",
        "          <mtext>if&#xA0;</mtext>\n",
        "          <mtext>min</mtext>\n",
        "          <mo>&#x2264;</mo>\n",
        "          <msub>\n",
        "            <mi>x</mi>\n",
        "            <mi>i</mi>\n",
        "          </msub>\n",
        "          <mo>&#x2264;</mo>\n",
        "          <mtext>max</mtext>\n",
        "          <mtext>&#xA0;</mtext>\n",
        "          <mtext>max</mtext>\n",
        "        </mtd>\n",
        "        <mtd>\n",
        "          <mtext>if&#xA0;</mtext>\n",
        "          <msub>\n",
        "            <mi>x</mi>\n",
        "            <mi>i</mi>\n",
        "          </msub>\n",
        "          <mo>&gt;</mo>\n",
        "          <mtext>max</mtext>\n",
        "        </mtd>\n",
        "      </mtr>\n",
        "    </mtable>\n",
        "    <mo data-mjx-texclass=\"CLOSE\" fence=\"true\" stretchy=\"true\" symmetric=\"true\"></mo>\n",
        "  </mrow>\n",
        "</math>\n",
        " \n",
        "\n",
        "torch.clamp takes in 3 arguments\n",
        "\n",
        "*   input which is the tensor on which the clamp is to be applied\n",
        "*   min the min value of the tensor after transformation\n",
        "*   max the max value of the tensor after transformation\n",
        "\n",
        "\n",
        "It should be noted the values already lying within the range is untouched."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "H_yu9DtqttM-",
        "outputId": "b0d7bb8f-ec32-40b2-8c54-1df74d8451c1"
      },
      "source": [
        "# Example 1 - working\n",
        "input_t = torch.randn(20)\n",
        "display(input_t)\n",
        "\n",
        "torch.clamp(input_t,-0.2,0.2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([ 0.0528, -1.7944,  1.4019,  1.9973,  1.4865,  3.2219,  0.8344,  0.5819,\n",
              "        -0.3843, -1.1803, -2.0581, -0.2031, -0.7404,  1.0038,  1.5646,  0.4750,\n",
              "         0.0927, -0.2654,  0.0426,  0.3310])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0528, -0.2000,  0.2000,  0.2000,  0.2000,  0.2000,  0.2000,  0.2000,\n",
              "        -0.2000, -0.2000, -0.2000, -0.2000, -0.2000,  0.2000,  0.2000,  0.2000,\n",
              "         0.0927, -0.2000,  0.0426,  0.2000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivOGeAwEttM-"
      },
      "source": [
        "In the above example the values are clamped to the min value of -0.2 and max of 0.2. the values that lie within the range are untouched."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "JlGoCGo0ttM_",
        "outputId": "f76591c4-7d9d-471b-8a15-d92a7db342f8"
      },
      "source": [
        "# Example 2 - working\n",
        "input_t = torch.randn(20).reshape(2,2,5)\n",
        "print(\"Before Clamping\")\n",
        "display(input_t)\n",
        "\n",
        "print(\"After Clamping\")\n",
        "display(torch.clamp(input_t,max=0.3))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before Clamping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[[ 0.9760,  1.4290, -0.4873,  0.3712, -1.2290],\n",
              "         [ 2.0886, -0.8333,  0.1474, -1.7361, -0.2043]],\n",
              "\n",
              "        [[-0.0825, -1.4008,  1.1304, -0.0438,  0.9690],\n",
              "         [-0.4801,  0.5569,  0.2388, -0.8573,  0.0413]]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "After Clamping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3000,  0.3000, -0.4873,  0.3000, -1.2290],\n",
              "         [ 0.3000, -0.8333,  0.1474, -1.7361, -0.2043]],\n",
              "\n",
              "        [[-0.0825, -1.4008,  0.3000, -0.0438,  0.3000],\n",
              "         [-0.4801,  0.3000,  0.2388, -0.8573,  0.0413]]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO1AOI0EttM_"
      },
      "source": [
        "In this example only the max value is clamped and the lower-bound is untouched."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "lRPDQSBMttM_",
        "outputId": "8af98485-1aae-45cf-d933-0cfa6eeb50a8"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "input_t = torch.randn(20).reshape(2,2,5)\n",
        "print(\"Before Clamping\")\n",
        "display(input_t)\n",
        "\n",
        "print(\"After Clamping\")\n",
        "display(torch.clamp(input_t))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before Clamping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1515,  0.5376,  0.3773, -0.5586,  0.8383],\n",
              "         [ 1.7634, -2.2353,  0.5859, -1.0368, -0.3764]],\n",
              "\n",
              "        [[-0.0500, -0.8921, -0.1028, -1.0448, -0.1495],\n",
              "         [-1.1194,  1.6196,  0.5938,  1.5513,  0.9477]]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "After Clamping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-983e123d0323>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After Clamping\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: At least one of 'min' or 'max' must not be None"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGCk7pmdttM_"
      },
      "source": [
        "This function breaks without max or min being passed to the argument.\n",
        "\n",
        "Can be used in optimizers to clip the value of the produced tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "DEWwF-2MttM_",
        "outputId": "75817505-0797-48da-9716-0ef817c42602"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/tosin-doc/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/tosin-doc/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NBRzPAottNA"
      },
      "source": [
        "## Function 5 - torch.cat()\n",
        "\n",
        "torch.cat concatenates the sequence of tensors in the given dimension.All tensors must have the same shape or be empty.\n",
        "\n",
        "torch.cat takes in 2 arguments\n",
        "\n",
        "tensors - The input tensor sequence which can be 2 or more tensors\n",
        "dim - The dimension along which the tensor should be concatenated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRy7S4fDttNA",
        "outputId": "74a28e46-a441-488d-d3c9-8fe11080605b"
      },
      "source": [
        "# Example 1 - working\n",
        "tensor1 = torch.arange(1,11).reshape(2,5)\n",
        "tensor2 = torch.arange(11,21).reshape(2,5)\n",
        "\n",
        "torch.cat((tensor1,tensor2), dim=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5, 11, 12, 13, 14, 15],\n",
              "        [ 6,  7,  8,  9, 10, 16, 17, 18, 19, 20]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52AgfsJkttNB"
      },
      "source": [
        "In the above case we have two tensor with shape 2,5 and trying to concatenate along the row. So this just horizontally stacks the tensor over the tensor1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tcuLrvgttNB",
        "outputId": "62ca1059-c9f7-4bb0-80c6-759d4b304b84"
      },
      "source": [
        "# Example 2 - working\n",
        "\n",
        "tensor1 = torch.arange(1,21).reshape(2,2,5)\n",
        "tensor2 = torch.arange(21,41).reshape(2,2,5)\n",
        "\n",
        "torch.cat((tensor1,tensor2), dim=1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1,  2,  3,  4,  5],\n",
              "         [ 6,  7,  8,  9, 10],\n",
              "         [21, 22, 23, 24, 25],\n",
              "         [26, 27, 28, 29, 30]],\n",
              "\n",
              "        [[11, 12, 13, 14, 15],\n",
              "         [16, 17, 18, 19, 20],\n",
              "         [31, 32, 33, 34, 35],\n",
              "         [36, 37, 38, 39, 40]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sw9gtkMttNB"
      },
      "source": [
        "In the above 3 dimensional tensor stacking of the values have happened along the row. each row value is exapaned to tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "J3X2vgqFttNB",
        "outputId": "7330254e-8c90-4b53-d6a2-659ba82377e4"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "\n",
        "tensor1 = torch.arange(1,21).reshape(2,2,5)\n",
        "tensor2 = torch.arange(21,41).reshape(2,2,5)\n",
        "\n",
        "torch.cat((tensor1,tensor2), dim=3)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-a55df25647fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtensor2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-3, 2], but got 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Obu1-xZttNB"
      },
      "source": [
        "Dimension did not match in this case. So the function fails. should be within the range of [-3,2]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "KaUvMqN8ttNC",
        "outputId": "e18d00e7-345d-43a4-b8b2-2a7a09c81969"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/tosin-doc/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/tosin-doc/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGBCyIunttNe"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "So In this notebook we have seen some exciting function which can ease out the speed of experimenting during model development. This is by no means the exhaustive list of functions available. For more details check out official documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLn_XZn3ttNe"
      },
      "source": [
        "## Reference Links\n",
        "Provide links to your references and other interesting articles about tensors\n",
        "* Official documentation for tensor operations: https://pytorch.org/docs/stable/torch.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "pjmDgDAKttNe",
        "outputId": "88133f2a-9c6b-4f70-af94-9375013bc8d3"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/tosin-doc/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/tosin-doc/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcpzH--8ttNh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}